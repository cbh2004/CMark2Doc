#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åŸºäºå¤§æ¨¡å‹è§†è§‰çš„æ•°å­¦å…¬å¼è¯†åˆ«å™¨
ä½¿ç”¨qwen2.5-vl-72b-instructæ¨¡å‹è¿›è¡Œå›¾ç‰‡è¯†åˆ«
"""

import os
import base64
from openai import OpenAI
from PIL import Image
import io
import httpx

class LLMVisionOCR:
    def __init__(self, api_key="sk-1be9881d5f1b472292b5cc1d1336065c"):
        self.api_key = api_key

        # åˆ›å»ºè‡ªå®šä¹‰HTTPå®¢æˆ·ç«¯ï¼Œè§£å†³SSLé—®é¢˜
        http_client = httpx.Client(
            verify=False,  # ç¦ç”¨SSLéªŒè¯
            timeout=60.0
        )

        self.client = OpenAI(
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            http_client=http_client
        )
        self.model = "qwen2.5-vl-72b-instruct"
        
    def recognize_formula(self, image_file):
        """ä½¿ç”¨å¤§æ¨¡å‹è¯†åˆ«æ•°å­¦å…¬å¼"""
        try:
            print("ğŸ¤– å¯åŠ¨å¤§æ¨¡å‹è§†è§‰è¯†åˆ«...")
            print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {image_file}")

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if isinstance(image_file, str):
                if not os.path.exists(image_file):
                    error_msg = f"æ–‡ä»¶ä¸å­˜åœ¨: {image_file}"
                    print(f"âŒ {error_msg}")
                    return {
                        'success': False,
                        'error': error_msg
                    }

                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(image_file)
                print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")

                if file_size == 0:
                    error_msg = "æ–‡ä»¶ä¸ºç©º"
                    print(f"âŒ {error_msg}")
                    return {
                        'success': False,
                        'error': error_msg
                    }

            # å¤„ç†å›¾ç‰‡
            image_data = self.prepare_image(image_file)
            if not image_data:
                return {
                    'success': False,
                    'error': 'å›¾ç‰‡å¤„ç†å¤±è´¥'
                }

            # è°ƒç”¨å¤§æ¨¡å‹
            result = self.call_vision_model(image_data)

            if result.get('success', False):
                print("âœ… å¤§æ¨¡å‹è¯†åˆ«æˆåŠŸ")
                return result
            else:
                print("âŒ å¤§æ¨¡å‹è¯†åˆ«å¤±è´¥")
                return result

        except Exception as e:
            print(f"âŒ å¤§æ¨¡å‹è¯†åˆ«å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': f'å¤§æ¨¡å‹è¯†åˆ«å‡ºé”™: {str(e)}'
            }
    
    def prepare_image(self, image_file):
        """å‡†å¤‡å›¾ç‰‡æ•°æ®"""
        try:
            print(f"ğŸ“· å¤„ç†å›¾ç‰‡: {image_file}")

            # åŠ è½½å›¾ç‰‡
            if isinstance(image_file, str):
                # è§„èŒƒåŒ–è·¯å¾„
                image_file = os.path.normpath(image_file)
                print(f"ğŸ“ è§„èŒƒåŒ–è·¯å¾„: {image_file}")

                if not os.path.exists(image_file):
                    print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_file}")
                    return None

                # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼æ‰“å¼€æ–‡ä»¶
                try:
                    # ç›´æ¥ä½¿ç”¨PILæ‰“å¼€ï¼Œä¸ä½¿ç”¨withè¯­å¥é¿å…æ–‡ä»¶å¥æŸ„é—®é¢˜
                    image = Image.open(image_file)
                    # ç«‹å³å¤åˆ¶å›¾ç‰‡æ•°æ®åˆ°å†…å­˜ï¼Œé¿å…æ–‡ä»¶å¥æŸ„é—®é¢˜
                    image = image.copy()
                    print(f"âœ… æˆåŠŸåŠ è½½å›¾ç‰‡: {image.size}")
                except Exception as open_error:
                    print(f"âŒ æ— æ³•æ‰“å¼€å›¾ç‰‡æ–‡ä»¶: {open_error}")
                    return None
            else:
                try:
                    image = Image.open(image_file)
                    image = image.copy()
                    print(f"âœ… æˆåŠŸåŠ è½½å›¾ç‰‡: {image.size}")
                except Exception as open_error:
                    print(f"âŒ æ— æ³•æ‰“å¼€å›¾ç‰‡: {open_error}")
                    return None

            print(f"ğŸ“ åŸå§‹å›¾ç‰‡å°ºå¯¸: {image.size}, æ¨¡å¼: {image.mode}")

            # è½¬æ¢ä¸ºRGBæ ¼å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
                print("ğŸ”„ å·²è½¬æ¢ä¸ºRGBæ ¼å¼")

            # è°ƒæ•´å›¾ç‰‡å¤§å° (å¦‚æœå¤ªå¤§çš„è¯)
            max_size = 1024
            if max(image.size) > max_size:
                ratio = max_size / max(image.size)
                new_size = tuple(int(dim * ratio) for dim in image.size)
                image = image.resize(new_size, Image.Resampling.LANCZOS)
                print(f"ğŸ“ è°ƒæ•´å›¾ç‰‡å°ºå¯¸: {image.size}")

            # è½¬æ¢ä¸ºbase64
            try:
                buffer = io.BytesIO()
                # ç¡®ä¿ä½¿ç”¨PNGæ ¼å¼ï¼Œå¹¶è®¾ç½®ä¼˜åŒ–å‚æ•°
                image.save(buffer, format='PNG', optimize=False)
                buffer.seek(0)
                image_data = buffer.getvalue()

                if len(image_data) == 0:
                    print("âŒ å›¾ç‰‡æ•°æ®ä¸ºç©º")
                    return None

                image_base64 = base64.b64encode(image_data).decode('utf-8')
                buffer.close()

                print(f"âœ… å›¾ç‰‡å¤„ç†å®Œæˆï¼Œbase64é•¿åº¦: {len(image_base64)}")
                return image_base64

            except Exception as save_error:
                print(f"âŒ å›¾ç‰‡ä¿å­˜å¤±è´¥: {save_error}")
                return None

        except Exception as e:
            print(f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def call_vision_model(self, image_base64):
        """è°ƒç”¨è§†è§‰æ¨¡å‹"""
        try:
            print(f"ğŸ”‘ ä½¿ç”¨API Key: {self.api_key[:10]}...")
            print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model}")

            # æ„å»ºæ¶ˆæ¯
            messages = [
                {
                    'role': 'system',
                    'content': '''ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦å…¬å¼è¯†åˆ«ä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æå›¾ç‰‡ä¸­çš„æ•°å­¦å…¬å¼ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¾“å‡ºï¼š

1. å‡†ç¡®è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ•°å­¦å…¬å¼
2. å°†è¯†åˆ«ç»“æœè½¬æ¢ä¸ºæ ‡å‡†çš„LaTeXæ ¼å¼
3. æ¯ä¸ªå…¬å¼ç”¨$$åŒ…å›´ï¼Œä¾‹å¦‚ï¼š$$å…¬å¼å†…å®¹$$
4. å¦‚æœæœ‰å¤šä¸ªå…¬å¼ï¼Œæ¯ä¸ªå…¬å¼å ä¸€è¡Œ
5. ä¿æŒå…¬å¼çš„åŸå§‹ç»“æ„å’Œç¬¦å·
6. ç‰¹åˆ«æ³¨æ„ï¼š
   - å¸Œè…Šå­—æ¯ï¼šÏƒåº”å†™æˆ\\sigmaï¼ŒÏ„åº”å†™æˆ\\tauç­‰
   - å‡½æ•°ï¼štanhåº”å†™æˆ\\tanhï¼Œsinåº”å†™æˆ\\sinç­‰
   - ä¸‹æ ‡ï¼šç”¨_{}è¡¨ç¤ºï¼Œå¦‚x_tå†™æˆx_{t}
   - ä¸Šæ ‡ï¼šç”¨^{}è¡¨ç¤º
   - åˆ†æ•°ï¼šç”¨\\frac{}{}è¡¨ç¤º
   - çŸ©é˜µï¼šç”¨\\begin{pmatrix}...\\end{pmatrix}è¡¨ç¤º
   - ä¹˜æ³•ï¼šå¯ä»¥ç”¨\\cdotæˆ–*è¡¨ç¤º

è¯·ç›´æ¥è¾“å‡ºLaTeXæ ¼å¼çš„å…¬å¼ï¼Œä¸è¦æ·»åŠ é¢å¤–çš„è§£é‡Šæ–‡å­—ã€‚'''
                },
                {
                    'role': 'user',
                    'content': [
                        {
                            'type': 'text',
                            'text': 'è¯·è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„æ•°å­¦å…¬å¼ï¼Œå¹¶è½¬æ¢ä¸ºLaTeXæ ¼å¼ï¼š'
                        },
                        {
                            'type': 'image_url',
                            'image_url': {
                                'url': f'data:image/png;base64,{image_base64}'
                            }
                        }
                    ]
                }
            ]

            print("ğŸ“¡ æ„å»ºAPIè¯·æ±‚...")
            print(f"ğŸ“Š å›¾ç‰‡æ•°æ®é•¿åº¦: {len(image_base64)} å­—ç¬¦")

            # è°ƒç”¨API
            print("ğŸ”„ æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹API...")
            try:
                completion = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=2000,
                    temperature=0.1  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´å‡†ç¡®çš„ç»“æœ
                )
                print("âœ… APIè°ƒç”¨æˆåŠŸ")
            except Exception as api_error:
                print(f"âŒ APIè°ƒç”¨å¤±è´¥: {api_error}")
                return {
                    'success': False,
                    'error': f'APIè°ƒç”¨å¤±è´¥: {str(api_error)}'
                }
            
            # å¤„ç†å“åº”
            if completion.choices and len(completion.choices) > 0:
                content = completion.choices[0].message.content
                
                if content and content.strip():
                    # ç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹çš„è¾“å‡ºï¼Œä¸è¿›è¡Œä¿®å¤
                    print(f"ğŸ“ å¤§æ¨¡å‹åŸå§‹è¾“å‡º:\n{content}")

                    return {
                        'success': True,
                        'latex': content.strip(),
                        'method': 'å¤§æ¨¡å‹è§†è§‰è¯†åˆ«',
                        'confidence': 'very_high',
                        'confidence_score': 95,
                        'raw_text': content,
                        'model': self.model
                    }
                else:
                    return {
                        'success': False,
                        'error': 'å¤§æ¨¡å‹è¿”å›ç©ºç»“æœ'
                    }
            else:
                return {
                    'success': False,
                    'error': 'å¤§æ¨¡å‹APIè°ƒç”¨å¤±è´¥'
                }
                
        except Exception as e:
            print(f"âŒ å¤§æ¨¡å‹APIè°ƒç”¨å¤±è´¥: {e}")
            return {
                'success': False,
                'error': f'å¤§æ¨¡å‹APIè°ƒç”¨å¤±è´¥: {str(e)}'
            }
    


# æµ‹è¯•å‡½æ•°
def test_llm_vision_ocr():
    """æµ‹è¯•å¤§æ¨¡å‹è§†è§‰OCR"""
    print("ğŸ§ª æµ‹è¯•å¤§æ¨¡å‹è§†è§‰OCR...")
    
    try:
        ocr = LLMVisionOCR()
        print("âœ… å¤§æ¨¡å‹è§†è§‰OCRåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“¡ ä½¿ç”¨æ¨¡å‹: {ocr.model}")
        print(f"ğŸ”‘ API Key: {ocr.api_key[:10]}...")
        
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æµ‹è¯•å›¾ç‰‡
        # result = ocr.recognize_formula("test_image.png")
        # print(f"æµ‹è¯•ç»“æœ: {result}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    test_llm_vision_ocr()
